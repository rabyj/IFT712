{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sk=0: using_sklearn=False, sk=1: using_sklearn=True\n",
    "- modele_gen=lineaire, sin ou tanh\n",
    "- nb_train: nombre de donnees d'entrainement\n",
    "- nb_test: nombre de donnees de test\n",
    "- bruit: amplitude du bruit appliqué aux données\n",
    "- M: degré du polynome de la fonction de base (recherche d'hyperparametre lorsque M<0) \n",
    "- lambda: lambda utilisé par le modele de Ridge ( learning rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "skl = 1\n",
    "modele_gen = \"sin\"\n",
    "nb_train = 80 \n",
    "nb_test = 20\n",
    "bruit = 0.3 # dispersion\n",
    "m = 10\n",
    "lamb = 0.001 # learning rate\n",
    "w = [0.3, 4.1]  # Parametres du modele generatif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gestion Donnees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generer_donnees():\n",
    "    \"\"\"\n",
    "    Fonction qui genere des donnees de test et d'entrainement.\n",
    "\n",
    "    modele_gen : 'lineaire', 'sin' ou 'tanh'\n",
    "    nb_train : nb de donnees d'entrainement\n",
    "    nb_test : nb de donnees de test\n",
    "    bruit : amplitude du bruit (superieur ou egale a zero\n",
    "    \"\"\"\n",
    "    np.random.seed(nb_train)\n",
    "    x_train = np.random.rand(nb_train)\n",
    "    x_test = np.random.rand(nb_test)\n",
    "    if modele_gen == 'lineaire':\n",
    "        t_train = w[0] + x_train * w[1] + np.random.randn(nb_train) * bruit\n",
    "        t_test = w[0] + x_test * w[1] + np.random.randn(nb_test) * bruit\n",
    "    elif modele_gen == 'sin':\n",
    "        t_train = np.sin(x_train * w[1] * 2) + np.random.randn(nb_train) * bruit\n",
    "        t_test = np.sin(x_test * w[1] * 2) + np.random.randn(nb_test) * bruit\n",
    "    else:\n",
    "        t_train = np.tanh((x_train - 0.5) * w[1] * 2) + np.random.randn(nb_train) * bruit\n",
    "        t_test = np.tanh((x_test - 0.5) * w[1] * 2) + np.random.randn(nb_test) * bruit\n",
    "\n",
    "    return x_train, t_train, x_test, t_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def afficher_donnees_et_modele( x, t, scatter=True):\n",
    "    \"\"\"\n",
    "    afficher des donnees\n",
    "\n",
    "    x : vecteur de donnees\n",
    "    t : vecteur de cibles\n",
    "    scatter : variable determinant si on doit afficher une courbe ou des points\n",
    "    \"\"\"\n",
    "    x_mod = np.arange(0, 1, 0.01)\n",
    "\n",
    "    if modele_gen == 'lineaire':\n",
    "        t_mod = w[0] + x_mod * w[1]\n",
    "    elif modele_gen == 'sin':\n",
    "        t_mod = np.sin(x_mod * w[1] * 2)\n",
    "    else:\n",
    "        t_mod = np.tanh((x_mod - 0.5) * w[1] * 2)\n",
    "\n",
    "    if scatter is True:\n",
    "        plt.scatter(x, t)\n",
    "    else:\n",
    "        idx = np.argsort(x)\n",
    "        plt.plot(x[idx], t[idx], 'g')\n",
    "\n",
    "    plt.plot(x_mod, t_mod, 'k')\n",
    "    plt.ylim(ymin=-1.5, ymax=4.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creer le gestionnaire de donnees et generer les donnees d'entraînement et de test\n",
    "[x_train, t_train, x_test, t_test] = generer_donnees()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.array([1,2,3])\n",
    "temp = temp.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2],\n",
       "       [3]])"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2,4):\n",
    "    temp = np.hstack((temp, (temp[:, 0] ** i).reshape((3, 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1,  1],\n",
       "       [ 2,  4,  8],\n",
       "       [ 3,  9, 27]])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fonction_base_polynomiale(x):\n",
    "    \"\"\"\n",
    "    Fonction de base qui projette la donnee x vers un espace polynomial tel que mentionne au chapitre 3.\n",
    "    Si x est un scalaire, alors phi_x sera un vecteur à M dimensions : (x^1,x^2,...,x^M)\n",
    "    Si x est un vecteur de N scalaires, alors phi_x sera un tableau 2D de taille NxM\n",
    "\n",
    "    NOTE : En mettant phi_x = x, on a une fonction de base lineaire qui fonctionne pour une regression lineaire\n",
    "    \"\"\"\n",
    "    # AJOUTER CODE ICI\n",
    "   \n",
    "    if(type(x) == int):\n",
    "        return np.array([x**i for i in range(1, m+1)]).reshape(m,1) # (x^1,x^2,...,x^M)\n",
    "    else:\n",
    "        x = x.reshape(-1,1)\n",
    "        for i in range(2,m+1):\n",
    "            x = np.hstack((x, (x[:, 0] ** i).reshape((len(x), 1))))\n",
    "        return x# 2D de taille NxM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test fonction_base_polynomiale : avec m = 10\n",
      " -> Si x est un scalaire : 2\n",
      "[[   2]\n",
      " [   4]\n",
      " [   8]\n",
      " [  16]\n",
      " [  32]\n",
      " [  64]\n",
      " [ 128]\n",
      " [ 256]\n",
      " [ 512]\n",
      " [1024]]\n",
      "shape :(10, 1)\n",
      " -> Si x est un vecteur de n scalaires : [2, 3]\n",
      "[[    2     4     8    16    32    64   128   256   512  1024]\n",
      " [    3     9    27    81   243   729  2187  6561 19683 59049]]\n",
      "Shape :(2, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"test fonction_base_polynomiale : avec m = 10\")\n",
    "print(\" -> Si x est un scalaire : 2\")\n",
    "print(fonction_base_polynomiale(2))\n",
    "print(\"shape :\"+str(fonction_base_polynomiale(2).shape))\n",
    "print(\" -> Si x est un vecteur de n scalaires : [2, 3]\")\n",
    "print(fonction_base_polynomiale(np.array([2, 3])))\n",
    "print(\"Shape :\"+str(fonction_base_polynomiale(np.array([2, 3])).shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recherche_hyperparametre(X, t):\n",
    "    \"\"\"\n",
    "    Validation croisee de type \"k-fold\" pour k=10 utilisee pour trouver \n",
    "    la meilleure valeur pour l'hyper-parametre M.\n",
    "\n",
    "    Le resultat est mis dans la variable M\n",
    "\n",
    "    X: vecteur de donnees\n",
    "    t: vecteur de cibles\n",
    "    \"\"\"\n",
    "    # AJOUTER CODE ICI\n",
    "    \n",
    "    scores = cross_val_score(linear_model.LinearRegression()\n",
    "                         ,fonction_base_polynomiale(x_train)\n",
    "                         , t_train, cv=LeaveOneOut(len(x_train)))\n",
    "    \n",
    "    M = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrainement(X, t, using_sklearn=False):\n",
    "    \"\"\"\n",
    "    Entraîne la regression lineaire sur l'ensemble d'entraînement forme des\n",
    "    entrees ``X`` (un tableau 2D Numpy, ou la n-ieme rangee correspond à \n",
    "    l'entree x_n) et des cibles ``t`` (un tableau 1D Numpy ou le\n",
    "    n-ieme element correspond à la cible t_n). L'entraînement doit\n",
    "    utiliser le poids de regularisation specifie par ``lamb``.\n",
    "\n",
    "    Cette methode doit assigner le champs ``w`` au vecteur\n",
    "    (tableau Numpy 1D) de taille D+1, tel que specifie à la section 3.1.4\n",
    "    du livre de Bishop.\n",
    "\n",
    "    Lorsque using_sklearn=True, vous devez utiliser la classe \"Ridge\" de \n",
    "    la librairie sklearn (voir http://scikit-learn.org/stable/modules/linear_model.html)\n",
    "\n",
    "    Lorsque using_sklearn=False, vous devez implementer l'equation 3.28 du\n",
    "    livre de Bishop. Il est suggere que le calcul de ``w`` n'utilise\n",
    "    pas d'inversion de matrice, mais utilise plutôt une procedure\n",
    "    de resolution de systeme d'equations lineaires (voir np.linalg.solve).\n",
    "\n",
    "    Aussi, la variable membre M sert à projeter les variables X vers un \n",
    "    espace polynomiale de degre M(voir fonction fonction_base_polynomiale())\n",
    "\n",
    "    NOTE IMPORTANTE : lorsque M <= 0, il faut trouver la bonne valeur de M\n",
    "\n",
    "    \"\"\"\n",
    "    #AJOUTER CODE ICI\n",
    "    if M <= 0:\n",
    "        recherche_hyperparametre(X, t)\n",
    "\n",
    "    phi_x = fonction_base_polynomiale(X)\n",
    "    w = [0, 1]\n",
    "    \n",
    "    # using_sklearn=True\n",
    "    if(using_sklearn==True):\n",
    "        reg = linear_model.Ridge(alpha=.5)\n",
    "        fit = reg.fit(phi_x, t)\n",
    "        w = fit.coef_\n",
    "        \n",
    "    # using_sklearn=False\n",
    "    if(using_sklearn==False):\n",
    "        iterations = 10000\n",
    "        w = np.random.rand(10)\n",
    "        cost_history = []\n",
    "        cost_history.append(costFunction(phi_x, t, w))\n",
    "\n",
    "        for iteration in range(1, iterations):\n",
    "            hypothesis = phi_x.dot(w)\n",
    "            loss = hypothesis-t\n",
    "            gradient = phi_x.T.dot(loss)/m\n",
    "            w = w - lamb*gradient\n",
    "            cost = np.sum((np.matmul(phi_x, w)-t)**2)/(2*m)\n",
    "            cost_history.append(cost)\n",
    "            print(cost)\n",
    "            if cost_history[iteration-1] - cost_history[iteration] < 0.0001:\n",
    "                break\n",
    "        plt.title('Cost Function J')\n",
    "        plt.xlabel('Number of iterations')\n",
    "        plt.ylabel('Cost')\n",
    "        plt.plot(cost_history)\n",
    "        plt.show()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costFunction(x, y, w):\n",
    "    cost = np.sum((np.matmul(x, w)-y)**2)/(2*m)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(x):\n",
    "    \"\"\"\n",
    "    Retourne la prediction de la regression lineaire\n",
    "    pour une entree, representee par un tableau 1D Numpy ``x``.\n",
    "\n",
    "    Cette methode suppose que la methode ``entrainement()``\n",
    "    a prealablement ete appelee. Elle doit utiliser le champs ``w``\n",
    "    afin de calculer la prediction y(x,w) (equation 3.1 et 3.3).\n",
    "    \"\"\"\n",
    "    # AJOUTER CODE ICI\n",
    "    \n",
    "    y = 1 + x.reshape(-1,1) @ W.reshape(1,-1)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erreur(t, prediction):\n",
    "    \"\"\"\n",
    "    Retourne l'erreur de la difference au carre entre\n",
    "    la cible ``t`` et la prediction ``prediction``.\n",
    "    \"\"\"\n",
    "    # AJOUTER CODE ICI\n",
    "    \n",
    "    # mean square error ????\n",
    "    \n",
    "    return (t-prediction)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warning(erreur_test, erreur_apprentissage, bruit):\n",
    "    \"\"\"\n",
    "    Fonction qui affiche un WARNING à l'ecran lorsque les erreurs obtenues en fonction du bruit\n",
    "    indique une possibilite de sur- ou de sous-apprentissage\n",
    "\n",
    "    erreur_test: erreur obtenue sur l'ensemble de test\n",
    "    erreur_apprentissage: erreur obtenue sur l'ensemble d'apprentissage\n",
    "    bruit: magnitude du bruit\n",
    "    \"\"\"\n",
    "    # AJOUTER CODE ICI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creer le gestionnaire de donnees et generer les donnees d'entraînement et de test\n",
    "[x_train, t_train, x_test, t_test] = generer_donnees()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.36415586182827\n",
      "8.194257020254174\n",
      "8.028121622668525\n",
      "7.865666081014277\n",
      "7.706808664156495\n",
      "7.551469456629877\n",
      "7.3995703183027\n",
      "7.251034844936851\n",
      "7.105788329624067\n",
      "6.963757725078852\n",
      "6.824871606769105\n",
      "6.689060136865811\n",
      "6.556255028993614\n",
      "6.426389513764462\n",
      "6.299398305076968\n",
      "6.175217567164417\n",
      "6.05378488237484\n",
      "5.935039219666876\n",
      "5.818920903805493\n",
      "5.705371585242059\n",
      "5.594334210663551\n",
      "5.485752994196011\n",
      "5.3795733892477395\n",
      "5.275742060978016\n",
      "5.174206859377437\n",
      "5.074916792946281\n",
      "4.9778220029576365\n",
      "4.882873738292282\n",
      "4.790024330832621\n",
      "4.699227171403254\n",
      "4.610436686246056\n",
      "4.5236083140178565\n",
      "4.438698483299136\n",
      "4.355664590602381\n",
      "4.27446497886899\n",
      "4.1950589164438945\n",
      "4.11740657651725\n",
      "4.041469017022863\n",
      "3.9672081609831684\n",
      "3.8945867772908658\n",
      "3.8235684619174926\n",
      "3.75411761953947\n",
      "3.6861994455723215\n",
      "3.6197799086040314\n",
      "3.5548257332186326\n",
      "3.491304383201397\n",
      "3.4291840451171205\n",
      "3.3684336122532317\n",
      "3.3090226689196087\n",
      "3.2509214750971873\n",
      "3.1941009514276058\n",
      "3.138532664536316\n",
      "3.0841888126817487\n",
      "3.0310422117232867\n",
      "2.9790662814009763\n",
      "2.928235031920031\n",
      "2.8785230508333752\n",
      "2.8299054902156\n",
      "2.782358054121849\n",
      "2.7358569863253215\n",
      "2.6903790583271876\n",
      "2.6459015576328717\n",
      "2.6024022762887795\n",
      "2.559859499673703\n",
      "2.518251995539207\n",
      "2.477559003293513\n",
      "2.4377602235234312\n",
      "2.3988358077490766\n",
      "2.360766348406186\n",
      "2.323532869050985\n",
      "2.28711681478266\n",
      "2.2515000428785963\n",
      "2.2166648136376637\n",
      "2.182593781426922\n",
      "2.1492699859272277\n",
      "2.1166768435733267\n",
      "2.0847981391841075\n",
      "2.0536180177787946\n",
      "2.0231209765749467\n",
      "1.99329185716423\n",
      "1.9641158378620034\n",
      "1.9355784262268667\n",
      "1.9076654517463894\n",
      "1.8803630586853306\n",
      "1.853657699092739\n",
      "1.827536125964403\n",
      "1.8019853865572037\n",
      "1.7769928158519903\n",
      "1.7525460301616835\n",
      "1.728632920881374\n",
      "1.7052416483772728\n",
      "1.6823606360114147\n",
      "1.6599785642991116\n",
      "1.638084365196199\n",
      "1.6166672165131928\n",
      "1.5957165364535415\n",
      "1.575221978273213\n",
      "1.55517342505892\n",
      "1.5355609846223521\n",
      "1.5163749845078354\n",
      "1.4976059671108959\n",
      "1.4792446849052725\n",
      "1.4612820957759598\n",
      "1.4437093584559308\n",
      "1.4265178280642368\n",
      "1.40969905174323\n",
      "1.393244764392706\n",
      "1.3771468844988175\n",
      "1.3613975100556488\n",
      "1.345988914577395\n",
      "1.330913543199132\n",
      "1.3161640088642144\n",
      "1.3017330885963652\n",
      "1.2876137198545883\n",
      "1.2737989969690577\n",
      "1.260282167656183\n",
      "1.2470566296110974\n",
      "1.2341159271758448\n",
      "1.221453748081582\n",
      "1.209063920263159\n",
      "1.196940408744462\n",
      "1.1850773125929512\n",
      "1.1734688619418545\n",
      "1.1621094150785174\n",
      "1.150993455597431\n",
      "1.140115589616514\n",
      "1.129470543055231\n",
      "1.1190531589731811\n",
      "1.1088583949678128\n",
      "1.0988813206299448\n",
      "1.08911711505582\n",
      "1.0795610644144258\n",
      "1.0702085595688602\n",
      "1.0610550937505399\n",
      "1.0520962602850763\n",
      "1.0433277503686729\n",
      "1.034745350893922\n",
      "1.0263449423239002\n",
      "1.0181224966134956\n",
      "1.0100740751769093\n",
      "1.0021958269003137\n",
      "0.9944839861986589\n",
      "0.9869348711156473\n",
      "0.9795448814659213\n",
      "0.972310497018519\n",
      "0.9652282757206894\n",
      "0.9582948519611639\n",
      "0.9515069348720108\n",
      "0.944861306668215\n",
      "0.9383548210241456\n",
      "0.9319844014860891\n",
      "0.925747039920051\n",
      "0.919639794994039\n",
      "0.9136597906940646\n",
      "0.9078042148731091\n",
      "0.9020703178323297\n",
      "0.8964554109337811\n",
      "0.8909568652439578\n",
      "0.8855721102074703\n",
      "0.8802986323501873\n",
      "0.8751339740111858\n",
      "0.8700757321028743\n",
      "0.8651215568986597\n",
      "0.8602691508475445\n",
      "0.855516267415062\n",
      "0.850860709949958\n",
      "0.8463003305760509\n",
      "0.8418330291087092\n",
      "0.8374567519953999\n",
      "0.833169491279774\n",
      "0.8289692835887637\n",
      "0.8248542091421835\n",
      "0.8208223907843333\n",
      "0.8168719930371122\n",
      "0.8130012211741715\n",
      "0.8092083203156347\n",
      "0.805491574542927\n",
      "0.8018493060332705\n",
      "0.7982798742134093\n",
      "0.7947816749321289\n",
      "0.7913531396511662\n",
      "0.7879927346540873\n",
      "0.7846989602727443\n",
      "0.7814703501309153\n",
      "0.7783054704047465\n",
      "0.7752029190996265\n",
      "0.7721613253431224\n",
      "0.769179348693625\n",
      "0.7662556784643527\n",
      "0.7633890330623727\n",
      "0.7605781593423065\n",
      "0.7578218319743926\n",
      "0.7551188528265876\n",
      "0.7524680503603962\n",
      "0.7498682790401207\n",
      "0.7473184187552355\n",
      "0.7448173742555941\n",
      "0.7423640745991815\n",
      "0.7399574726121374\n",
      "0.7375965443607737\n",
      "0.7352802886353216\n",
      "0.7330077264451472\n",
      "0.7307779005251825\n",
      "0.728589874853319\n",
      "0.7264427341785246\n",
      "0.7243355835594422\n",
      "0.7222675479132397\n",
      "0.7202377715744814\n",
      "0.7182454178638001\n",
      "0.7162896686661501\n",
      "0.7143697240184317\n",
      "0.7124848017062738\n",
      "0.7106341368697772\n",
      "0.7088169816180134\n",
      "0.7070326046520907\n",
      "0.7052802908965914\n",
      "0.7035593411391974\n",
      "0.7018690716783228\n",
      "0.7002088139785734\n",
      "0.6985779143338597\n",
      "0.6969757335379964\n",
      "0.695401646562616\n",
      "0.693855042242242\n",
      "0.6923353229663537\n",
      "0.6908419043782958\n",
      "0.6893742150808745\n",
      "0.6879316963484945\n",
      "0.686513801845692\n",
      "0.685119997351918\n",
      "0.6837497604924384\n",
      "0.6824025804752114\n",
      "0.6810779578336087\n",
      "0.6797754041748545\n",
      "0.6784944419340512\n",
      "0.6772346041336711\n",
      "0.6759954341483895\n",
      "0.674776485475143\n",
      "0.6735773215082961\n",
      "0.6723975153198015\n",
      "0.6712366494442461\n",
      "0.67009431566867\n",
      "0.6689701148270565\n",
      "0.6678636565993866\n",
      "0.6667745593151577\n",
      "0.665702449761268\n",
      "0.6646469629941673\n",
      "0.6636077421561816\n",
      "0.6625844382959192\n",
      "0.6615767101926646\n",
      "0.660584224184675\n",
      "0.6596066540012896\n",
      "0.6586436805987713\n",
      "0.6576949919997921\n",
      "0.6567602831364868\n",
      "0.6558392556969916\n",
      "0.6549316179753931\n",
      "0.6540370847250101\n",
      "0.6531553770149342\n",
      "0.6522862220897594\n",
      "0.6514293532324247\n",
      "0.6505845096301069\n",
      "0.6497514362430902\n",
      "0.6489298836765498\n",
      "0.6481196080551848\n",
      "0.6473203709006334\n",
      "0.6465319390116148\n",
      "0.6457540843467309\n",
      "0.6449865839098727\n",
      "0.6442292196381738\n",
      "0.6434817782924496\n",
      "0.6427440513500735\n",
      "0.6420158349002316\n",
      "0.6412969295415044\n",
      "0.6405871402817235\n",
      "0.6398862764400539\n",
      "0.6391941515512503\n",
      "0.6385105832720406\n",
      "0.6378353932895907\n",
      "0.637168407232\n",
      "0.6365094545807877\n",
      "0.6358583685853212\n",
      "0.6352149861791475\n",
      "0.6345791478981816\n",
      "0.6339506978007128\n",
      "0.6333294833891887\n",
      "0.6327153555337358\n",
      "0.63210816839738\n",
      "0.6315077793629271\n",
      "0.630914048961469\n",
      "0.6303268408024771\n",
      "0.6297460215054492\n",
      "0.6291714606330748\n",
      "0.6286030306258843\n",
      "0.6280406067383517\n",
      "0.6274840669764143\n",
      "0.6269332920363831\n",
      "0.6263881652452084\n",
      "0.625848572502072\n",
      "0.6253144022212795\n",
      "0.6247855452764183\n",
      "0.6242618949457575\n",
      "0.6237433468588607\n",
      "0.623229798944385\n",
      "0.6227211513790382\n",
      "0.6222173065376719\n",
      "0.6217181689444818\n",
      "0.6212236452252925\n",
      "0.6207336440609021\n",
      "0.6202480761414643\n",
      "0.6197668541218813\n",
      "0.619289892578191\n",
      "0.6188171079649202\n",
      "0.6183484185733865\n",
      "0.6178837444909265\n",
      "0.6174230075610294\n",
      "0.6169661313443557\n",
      "0.6165130410806231\n",
      "0.6160636636513381\n",
      "0.6156179275433555\n",
      "0.615175762813248\n",
      "0.6147371010524667\n",
      "0.6143018753532757\n",
      "0.6138700202754436\n",
      "0.6134414718136746\n",
      "0.6130161673657637\n",
      "0.6125940457014578\n",
      "0.6121750469320112\n",
      "0.6117591124804141\n",
      "0.6113461850522851\n",
      "0.6109362086074087\n",
      "0.610529128331906\n",
      "0.6101248906110233\n",
      "0.609723443002524\n",
      "0.6093247342106745\n",
      "0.6089287140608042\n",
      "0.6085353334744339\n",
      "0.6081445444449539\n",
      "0.6077563000138454\n",
      "0.6073705542474268\n",
      "0.6069872622141194\n",
      "0.6066063799622162\n",
      "0.6062278644981455\n",
      "0.6058516737652166\n",
      "0.6054777666228391\n",
      "0.6051061028262013\n",
      "0.6047366430064023\n",
      "0.6043693486510249\n",
      "0.6040041820851393\n",
      "0.6036411064527281\n",
      "0.6032800856985274\n",
      "0.6029210845502666\n",
      "0.6025640685013058\n",
      "0.602209003793658\n",
      "0.6018558574013888\n",
      "0.6015045970143833\n",
      "0.6011551910224752\n",
      "0.600807608499929\n",
      "0.6004618191902641\n",
      "0.600117793491419\n",
      "0.5997755024412429\n",
      "0.5994349177033113\n",
      "0.5990960115530544\n",
      "0.5987587568641963\n",
      "0.5984231270954938\n",
      "0.5980890962777692\n",
      "0.5977566390012328\n",
      "0.5974257304030859\n",
      "0.5970963461553993\n",
      "0.5967684624532612\n",
      "0.5964420560031881\n",
      "0.596117104011794\n",
      "0.595793584174709\n",
      "0.5954714746657475\n",
      "0.5951507541263134\n",
      "0.5948314016550433\n",
      "0.5945133967976783\n",
      "0.5941967195371615\n",
      "0.5938813502839542\n",
      "0.5935672698665693\n",
      "0.5932544595223126\n",
      "0.5929429008882316\n",
      "0.5926325759922646\n",
      "0.5923234672445858\n",
      "0.5920155574291436\n",
      "0.5917088296953863\n",
      "0.5914032675501717\n",
      "0.5910988548498562\n",
      "0.5907955757925605\n",
      "0.5904934149106053\n",
      "0.5901923570631162\n",
      "0.5898923874287939\n",
      "0.5895934914988418\n",
      "0.589295655070054\n",
      "0.588998864238055\n",
      "0.5887031053906899\n",
      "0.588408365201561\n",
      "0.5881146306237094\n",
      "0.5878218888834346\n",
      "0.5875301274742538\n",
      "0.5872393341509934\n",
      "0.5869494969240125\n",
      "0.5866606040535556\n",
      "0.5863726440442278\n",
      "0.5860856056395974\n",
      "0.5857994778169131\n",
      "0.5855142497819422\n",
      "0.5852299109639226\n",
      "0.5849464510106254\n",
      "0.5846638597835294\n",
      "0.5843821273531009\n",
      "0.5841012439941794\n",
      "0.5838212001814655\n",
      "0.5835419865851085\n",
      "0.5832635940663924\n",
      "0.5829860136735184\n",
      "0.5827092366374793\n",
      "0.5824332543680273\n",
      "0.5821580584497298\n",
      "0.5818836406381145\n",
      "0.581609992855898\n",
      "0.5813371071893003\n",
      "0.5810649758844393\n",
      "0.5807935913438061\n",
      "0.5805229461228196\n",
      "0.5802530329264552\n",
      "0.5799838446059505\n",
      "0.5797153741555835\n",
      "0.5794476147095213\n",
      "0.579180559538741\n",
      "0.5789142020480161\n",
      "0.5786485357729727\n",
      "0.5783835543772087\n",
      "0.5781192516494779\n",
      "0.5778556215009372\n",
      "0.5775926579624542\n",
      "0.5773303551819742\n",
      "0.5770687074219469\n",
      "0.5768077090568084\n",
      "0.5765473545705215\n",
      "0.5762876385541678\n",
      "0.5760285557035958\n",
      "0.5757701008171197\n",
      "0.5755122687932696\n",
      "0.5752550546285919\n",
      "0.5749984534154979\n",
      "0.5747424603401612\n",
      "0.5744870706804608\n",
      "0.57423227980397\n",
      "0.5739780831659905\n",
      "0.5737244763076295\n",
      "0.5734714548539198\n",
      "0.573219014511982\n",
      "0.5729671510692256\n",
      "0.5727158603915934\n",
      "0.5724651384218411\n",
      "0.5722149811778582\n",
      "0.5719653847510242\n",
      "0.5717163453046016\n",
      "0.5714678590721659\n",
      "0.5712199223560683\n",
      "0.5709725315259343\n",
      "0.5707256830171941\n",
      "0.5704793733296478\n",
      "0.5702335990260595\n",
      "0.5699883567307853\n",
      "0.5697436431284297\n",
      "0.5694994549625333\n",
      "0.5692557890342889\n",
      "0.5690126422012854\n",
      "0.5687700113762815\n",
      "0.5685278935260046\n",
      "0.5682862856699777\n",
      "0.5680451848793708\n",
      "0.56780458827588\n",
      "0.5675644930306294\n",
      "0.5673248963630982\n",
      "0.5670857955400721\n",
      "0.5668471878746167\n",
      "0.5666090707250749\n",
      "0.5663714414940854\n",
      "0.5661342976276243\n",
      "0.5658976366140669\n",
      "0.56566145598327\n",
      "0.5654257533056761\n",
      "0.5651905261914362\n",
      "0.5649557722895515\n",
      "0.5647214892870366\n",
      "0.5644876749080979\n",
      "0.5642543269133335\n",
      "0.5640214430989481\n",
      "0.5637890212959867\n",
      "0.5635570593695853\n",
      "0.5633255552182383\n",
      "0.563094506773081\n",
      "0.5628639119971889\n",
      "0.5626337688848928\n",
      "0.5624040754611087\n",
      "0.5621748297806821\n",
      "0.5619460299277473\n",
      "0.5617176740151013\n",
      "0.5614897601835906\n",
      "0.5612622866015122\n",
      "0.5610352514640282\n",
      "0.560808652992592\n",
      "0.5605824894343889\n",
      "0.5603567590617884\n",
      "0.5601314601718075\n",
      "0.559906591085588\n",
      "0.5596821501478841\n",
      "0.5594581357265608\n",
      "0.5592345462121051\n",
      "0.5590113800171462\n",
      "0.558788635575988\n",
      "0.5585663113441501\n",
      "0.558344405797921\n",
      "0.5581229174339194\n",
      "0.5579018447686664\n",
      "0.5576811863381664\n",
      "0.5574609406974981\n",
      "0.5572411064204129\n",
      "0.557021682098945\n",
      "0.556802666343027\n",
      "0.5565840577801161\n",
      "0.5563658550548279\n",
      "0.5561480568285779\n",
      "0.5559306617792317\n",
      "0.5557136686007624\n",
      "0.5554970760029162\n",
      "0.5552808827108839\n",
      "0.5550650874649815\n",
      "0.5548496890203368\n",
      "0.5546346861465831\n",
      "0.5544200776275596\n",
      "0.5542058622610192\n",
      "0.5539920388583408\n",
      "0.5537786062442505\n",
      "0.5535655632565473\n",
      "0.5533529087458346\n",
      "0.5531406415752592\n",
      "0.5529287606202548\n",
      "0.5527172647682911\n",
      "0.5525061529186294\n",
      "0.5522954239820828\n",
      "0.5520850768807815\n",
      "0.5518751105479447\n",
      "0.5516655239276549\n",
      "0.5514563159746408\n",
      "0.5512474856540612\n",
      "0.5510390319412963\n",
      "0.5508309538217426\n",
      "0.5506232502906125\n",
      "0.5504159203527381\n",
      "0.5502089630223798\n",
      "0.5500023773230376\n",
      "0.54979616228727\n",
      "0.5495903169565125\n",
      "0.5493848403809032\n",
      "0.5491797316191113\n",
      "0.548974989738169\n",
      "0.5487706138133078\n",
      "0.5485666029277976\n",
      "0.5483629561727901\n",
      "0.548159672647165\n",
      "0.5479567514573807\n",
      "0.5477541917173262\n",
      "0.5475519925481785\n",
      "0.5473501530782618\n",
      "0.5471486724429104\n",
      "0.5469475497843337\n",
      "0.5467467842514857\n",
      "0.5465463749999356\n",
      "0.5463463211917433\n",
      "0.5461466219953348\n",
      "0.5459472765853834\n",
      "0.5457482841426916\n",
      "0.5455496438540758\n",
      "0.5453513549122538\n",
      "0.5451534165157357\n",
      "0.5449558278687148\n",
      "0.5447585881809633\n",
      "0.5445616966677291\n",
      "0.5443651525496348\n",
      "0.5441689550525797\n",
      "0.5439731034076427\n",
      "0.5437775968509886\n",
      "0.543582434623776\n",
      "0.5433876159720661\n",
      "0.5431931401467358\n",
      "0.5429990064033906\n",
      "0.5428052140022802\n",
      "0.5426117622082162\n",
      "0.5424186502904906\n",
      "0.5422258775227984\n",
      "0.5420334431831582\n",
      "0.5418413465538379\n",
      "0.5416495869212804\n",
      "0.5414581635760314\n",
      "0.541267075812668\n",
      "0.5410763229297305\n",
      "0.5408859042296532\n",
      "0.5406958190186993\n",
      "0.5405060666068959\n",
      "0.5403166463079696\n",
      "0.5401275574392856\n",
      "0.5399387993217869\n",
      "0.5397503712799333\n",
      "0.5395622726416455\n",
      "0.5393745027382466\n",
      "0.5391870609044073\n",
      "0.5389999464780912\n",
      "0.5388131588005012\n",
      "0.5386266972160281\n",
      "0.5384405610721987\n",
      "0.5382547497196271\n",
      "0.5380692625119646\n",
      "0.5378840988058528\n",
      "0.5376992579608764\n",
      "0.5375147393395177\n",
      "0.5373305423071117\n",
      "0.5371466662318027\n",
      "0.5369631104845007\n",
      "0.5367798744388401\n",
      "0.5365969574711382\n",
      "0.5364143589603556\n",
      "0.5362320782880563\n",
      "0.5360501148383694\n",
      "0.5358684679979521\n",
      "0.5356871371559515\n",
      "0.5355061217039703\n",
      "0.5353254210360295\n",
      "0.5351450345485358\n",
      "0.5349649616402464\n",
      "0.5347852017122368\n",
      "0.5346057541678675\n",
      "0.5344266184127534\n",
      "0.5342477938547321\n",
      "0.5340692799038332\n",
      "0.5338910759722497\n",
      "0.5337131814743079\n",
      "0.5335355958264388\n",
      "0.5333583184471514\n",
      "0.5331813487570043\n",
      "0.5330046861785789\n",
      "0.5328283301364543\n",
      "0.5326522800571809\n",
      "0.5324765353692549\n",
      "0.5323010955030949\n",
      "0.5321259598910169\n",
      "0.5319511279672116\n",
      "0.5317765991677201\n",
      "0.5316023729304126\n",
      "0.5314284486949657\n",
      "0.5312548259028409\n",
      "0.531081503997263\n",
      "0.5309084824232\n",
      "0.5307357606273426\n",
      "0.5305633380580839\n",
      "0.5303912141655002\n",
      "0.530219388401332\n",
      "0.5300478602189649\n",
      "0.529876629073412\n",
      "0.5297056944212952\n",
      "0.529535055720828\n",
      "0.5293647124317984\n",
      "0.5291946640155514\n",
      "0.5290249099349733\n",
      "0.5288554496544753\n",
      "0.5286862826399771\n",
      "0.5285174083588919\n",
      "0.5283488262801113\n",
      "0.5281805358739897\n",
      "0.5280125366123304\n",
      "0.5278448279683708\n",
      "0.5276774094167689\n",
      "0.5275102804335885\n",
      "0.5273434404962872\n",
      "0.527176889083702\n",
      "0.5270106256760366\n",
      "0.5268446497548495\n",
      "0.5266789608030402\n",
      "0.5265135583048383\n",
      "0.5263484417457905\n",
      "0.52618361061275\n",
      "0.5260190643938637\n",
      "0.525854802578562\n",
      "0.5256908246575475\n",
      "0.5255271301227836\n",
      "0.5253637184674849\n",
      "0.5252005891861057\n",
      "0.5250377417743307\n",
      "0.5248751757290642\n",
      "0.5247128905484212\n",
      "0.5245508857317167\n",
      "0.5243891607794573\n",
      "0.524227715193331\n",
      "0.5240665484761987\n",
      "0.5239056601320853\n",
      "0.5237450496661705\n",
      "0.5235847165847807\n",
      "0.5234246603953799\n",
      "0.5232648806065626\n",
      "0.5231053767280442\n",
      "0.5229461482706548\n",
      "0.5227871947463291\n",
      "0.522628515668101\n",
      "0.5224701105500948\n",
      "0.5223119789075181\n",
      "0.5221541202566544\n",
      "0.5219965341148565\n",
      "0.5218392200005386\n",
      "0.5216821774331705\n",
      "0.5215254059332699\n",
      "0.5213689050223963\n",
      "0.5212126742231445\n",
      "0.521056713059138\n",
      "0.5209010210550228\n",
      "0.5207455977364612\n",
      "0.5205904426301259\n",
      "0.5204355552636937\n",
      "0.5202809351658402\n",
      "0.5201265818662337\n",
      "0.5199724948955295\n",
      "0.5198186737853644\n",
      "0.5196651180683511\n",
      "0.5195118272780735\n",
      "0.5193588009490808\n",
      "0.5192060386168821\n",
      "0.5190535398179421\n",
      "0.5189013040896755\n",
      "0.5187493309704424\n",
      "0.5185976199995428\n",
      "0.518446170717213\n",
      "0.5182949826646197\n",
      "0.5181440553838562\n",
      "0.5179933884179374\n",
      "0.5178429813107958\n",
      "0.5176928336072764\n",
      "0.5175429448531332\n",
      "0.5173933145950246\n",
      "0.5172439423805086\n",
      "0.5170948277580398\n",
      "0.5169459702769647\n",
      "0.5167973694875174\n",
      "0.5166490249408167\n",
      "0.5165009361888608\n",
      "0.516353102784525\n",
      "0.5162055242815565\n",
      "0.5160582002345722\n",
      "0.5159111301990535\n",
      "0.5157643137313441\n",
      "0.5156177503886454\n",
      "0.5154714397290133\n",
      "0.5153253813113556\n",
      "0.5151795746954273\n",
      "0.5150340194418279\n",
      "0.5148887151119984\n",
      "0.5147436612682176\n",
      "0.5145988574735988\n",
      "0.5144543032920872\n",
      "0.5143099982884565\n",
      "0.5141659420283053\n",
      "0.5140221340780551\n",
      "0.5138785740049466\n",
      "0.5137352613770368\n",
      "0.5135921957631965\n",
      "0.5134493767331068\n",
      "0.5133068038572569\n",
      "0.5131644767069409\n",
      "0.513022394854255\n",
      "0.5128805578720956\n",
      "0.5127389653341551\n",
      "0.5125976168149204\n",
      "0.5124565118896703\n",
      "0.5123156501344722\n",
      "0.5121750311261799\n",
      "0.5120346544424313\n",
      "0.5118945196616455\n",
      "0.5117546263630206\n",
      "0.5116149741265315\n",
      "0.5114755625329263\n",
      "0.5113363911637255\n",
      "0.5111974596012189\n",
      "0.5110587674284629\n",
      "0.510920314229279\n",
      "0.5107820995882509\n",
      "0.5106441230907224\n",
      "0.5105063843227955\n",
      "0.5103688828713275\n",
      "0.5102316183239296\n",
      "0.5100945902689642\n",
      "0.5099577982955433\n",
      "0.5098212419935255\n",
      "0.509684920953515\n",
      "0.5095488347668583\n",
      "0.5094129830256439\n",
      "0.5092773653226979\n",
      "0.5091419812515843\n",
      "0.5090068304066016\n",
      "0.5088719123827812\n",
      "0.5087372267758858\n",
      "0.508602773182407\n",
      "0.5084685511995632\n",
      "0.5083345604252987\n",
      "0.5082008004582805\n",
      "0.5080672708978978\n",
      "0.507933971344259\n",
      "0.5078009013981906\n",
      "0.5076680606612344\n",
      "0.5075354487356477\n",
      "0.5074030652243993\n",
      "0.507270909731169\n",
      "0.5071389818603456\n",
      "0.5070072812170248\n",
      "0.506875807407008\n",
      "0.5067445600368004\n",
      "0.5066135387136093\n",
      "0.5064827430453424\n",
      "0.5063521726406058\n",
      "0.5062218271087031\n",
      "0.5060917060596334\n",
      "0.505961809104089\n",
      "0.505832135853455\n",
      "0.5057026859198068\n",
      "0.5055734589159087\n",
      "0.5054444544552128\n",
      "0.5053156721518566\n",
      "0.5051871116206623\n",
      "0.5050587724771345\n",
      "0.5049306543374591\n",
      "0.5048027568185018\n",
      "0.5046750795378063\n",
      "0.5045476221135929\n",
      "0.5044203841647573\n",
      "0.5042933653108687\n",
      "0.5041665651721685\n",
      "0.5040399833695689\n",
      "0.5039136195246513\n",
      "0.5037874732596648\n",
      "0.5036615441975252\n",
      "0.5035358319618128\n",
      "0.5034103361767719\n",
      "0.5032850564673087\n",
      "0.5031599924589901\n",
      "0.5030351437780423\n",
      "0.5029105100513493\n",
      "0.5027860909064519\n",
      "0.5026618859715459\n",
      "0.5025378948754812\n",
      "0.5024141172477595\n",
      "0.5022905527185342\n",
      "0.502167200918608\n",
      "0.5020440614794326\n",
      "0.5019211340331061\n",
      "0.5017984182123728\n",
      "0.5016759136506213\n",
      "0.5015536199818834\n",
      "0.5014315368408326\n",
      "0.5013096638627832\n",
      "0.5011880006836884\n",
      "0.5010665469401394\n",
      "0.5009453022693644\n",
      "0.5008242663092268\n",
      "0.5007034386982242\n",
      "0.5005828190754869\n",
      "0.5004624070807772\n",
      "0.5003422023544875\n",
      "0.5002222045376393\n",
      "0.5001024132718823\n",
      "0.4999828281994927\n",
      "0.4998634489633719\n",
      "0.49974427520704623\n",
      "0.4996253065746642\n",
      "0.4995065427109967\n",
      "0.4993879832614351\n",
      "0.49926962787198975\n",
      "0.49915147618928984\n",
      "0.4990335278605812\n",
      "0.4989157825337255\n",
      "0.4987982398571993\n",
      "0.49868089948009225\n",
      "0.49856376105210654\n",
      "0.4984468242235554\n",
      "0.498330088645362\n",
      "0.4982135539690583\n",
      "0.49809721984678423\n",
      "0.49798108593128576\n",
      "0.49786515187591435\n",
      "0.49774941733462585\n",
      "0.4976338819619791\n",
      "0.49751854541313456\n",
      "0.49740340734385385\n",
      "0.49728846741049837\n",
      "0.4971737252700278\n",
      "0.4970591805799992\n",
      "0.4969448329985662\n",
      "0.49683068218447757\n",
      "0.4967167277970761\n",
      "0.49660296949629784\n",
      "0.49648940694267035\n",
      "0.4963760397973121\n",
      "0.49626286772193157\n",
      "0.49614989037882545\n",
      "0.4960371074308784\n",
      "0.4959245185415611\n",
      "0.4958121233749299\n",
      "0.49569992159562537\n",
      "0.49558791286887116\n",
      "0.4954760968604733\n",
      "0.4953644732368188\n",
      "0.4952530416648747\n",
      "0.495141801812187\n",
      "0.4950307533468795\n",
      "0.494919895937653\n",
      "0.4948092292537843\n",
      "0.4946987529651244\n",
      "0.49458846674209855\n",
      "0.4944783702557043\n",
      "0.49436846317751104\n",
      "0.49425874517965873\n",
      "0.49414921593485667\n",
      "0.494039875116383\n",
      "0.49393072239808306\n",
      "0.4938217574543689\n",
      "0.49371297996021796\n",
      "0.493604389591172\n",
      "0.4934959860233363\n",
      "0.49338776893337843\n",
      "0.4932797379985276\n",
      "0.49317189289657304\n",
      "0.49306423330586363\n",
      "0.49295675890530644\n",
      "0.492849469374366\n",
      "0.49274236439306324\n",
      "0.4926354436419743\n",
      "0.4925287068022298\n",
      "0.4924221535555137\n",
      "0.4923157835840626\n",
      "0.49220959657066404\n",
      "0.49210359219865635\n",
      "0.491997770151927\n",
      "0.49189213011491245\n",
      "0.49178667177259605\n",
      "0.49168139481050793\n",
      "0.4915762989147237\n",
      "0.49147138377186367\n",
      "0.4913666490690914\n",
      "0.49126209449411357\n",
      "0.49115771973517813\n",
      "0.4910535244810739\n",
      "0.4909495084211293\n",
      "0.4908456712452118\n",
      "0.4907420126437264\n",
      "0.4906385323076153\n",
      "0.4905352299283564\n",
      "0.49043210519796254\n",
      "0.49032915780898084\n",
      "0.49022638745449115\n",
      "0.49012379382810584\n",
      "0.4900213766239682\n",
      "0.48991913553675204\n",
      "0.4898170702616603\n",
      "0.4897151804944245\n",
      "0.4896134659313033\n",
      "0.48951192626908213\n",
      "0.4894105612050721\n",
      "0.489309370437109\n",
      "0.489208353663552\n",
      "0.4891075105832835\n",
      "0.48900684089570773\n",
      "0.4889063443007499\n",
      "0.4888060204988552\n",
      "0.48870586919098813\n",
      "0.4886058900786313\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Entrainement du modele de regression\n",
    "entrainement(x_train, t_train, using_sklearn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions sur les ensembles d'entrainement et de test\n",
    "predictions_train = prediction(x_train)\n",
    "predictions_test = prediction(x_train)\n",
    "#predictions_train = np.array([prediction(x) for x in x_train])\n",
    "#predictions_test = np.array([prediction(x) for x in x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur d'entraînement : 1.26\n",
      "Erreur de test : 1.19\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calcul des erreurs\n",
    "erreurs_entrainement = np.array([erreur(t_n, p_n)\n",
    "                                 for t_n, p_n in zip(t_train, predictions_train)])\n",
    "erreurs_test = np.array([erreur(t_n, p_n)\n",
    "                         for t_n, p_n in zip(t_test, predictions_test)])\n",
    "\n",
    "print(\"Erreur d'entraînement :\", \"%.2f\" % erreurs_entrainement.mean())\n",
    "print(\"Erreur de test :\", \"%.2f\" % erreurs_test.mean())\n",
    "print(\"\")\n",
    "\n",
    "warning(erreurs_test.mean(), erreurs_entrainement.mean(), bruit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1, 10)"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_range.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y can be no greater than 2-D, but have shapes (100,) and (100, 1, 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-501-ed22b9c9b079>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mafficher_donnees_et_modele\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpredictions_range\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mafficher_donnees_et_modele\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions_range\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mm\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-211-6fe29c03bad1>\u001b[0m in \u001b[0;36mafficher_donnees_et_modele\u001b[1;34m(x, t, scatter)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'g'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_mod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_mod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'k'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\chatbot\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   3356\u001b[0m                       mplDeprecation)\n\u001b[0;32m   3357\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3358\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3359\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3360\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\chatbot\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1853\u001b[0m                         \u001b[1;34m\"the Matplotlib list!)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1854\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1855\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1856\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1857\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\chatbot\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1525\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_alias_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1527\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1528\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1529\u001b[0m             \u001b[0mlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\chatbot\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    404\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mseg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    407\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mseg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\chatbot\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    381\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 383\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'plot'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\chatbot\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m    243\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n\u001b[1;32m--> 245\u001b[1;33m                              \"shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x and y can be no greater than 2-D, but have shapes (100,) and (100, 1, 10)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Affichage\n",
    "afficher_donnees_et_modele(x_train, t_train, True)\n",
    "predictions_range = np.array([prediction(x) for x in np.arange(0, 1, 0.01)])\n",
    "afficher_donnees_et_modele(np.arange(0, 1, 0.01), predictions_range, False)\n",
    "\n",
    "if m >= 0:\n",
    "    plt.suptitle('Resultat SANS recherche d\\'hyperparametres')\n",
    "else:\n",
    "    plt.suptitle('Resultat AVEC recherche d\\'hyperparametres')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
