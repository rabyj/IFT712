{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sk=0: using_sklearn=False, sk=1: using_sklearn=True\n",
    "- modele_gen=lineaire, sin ou tanh\n",
    "- nb_train: nombre de donnees d'entrainement\n",
    "- nb_test: nombre de donnees de test\n",
    "- bruit: amplitude du bruit appliqué aux données\n",
    "- M: degré du polynome de la fonction de base (recherche d'hyperparametre lorsque M<0) \n",
    "- lambda: lambda utilisé par le modele de Ridge ( learning rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "skl = 1\n",
    "modele_gen = \"sin\"\n",
    "nb_train = 80\n",
    "nb_test = 20\n",
    "bruit = 0.3 # dispersion\n",
    "m = 20\n",
    "lamb = 0.09 # learning rate\n",
    "w = [0.3, 4.1]  # Parametres du modele generatif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gestion Donnees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generer_donnees():\n",
    "    \"\"\"\n",
    "    Fonction qui genere des donnees de test et d'entrainement.\n",
    "\n",
    "    modele_gen : 'lineaire', 'sin' ou 'tanh'\n",
    "    nb_train : nb de donnees d'entrainement\n",
    "    nb_test : nb de donnees de test\n",
    "    bruit : amplitude du bruit (superieur ou egale a zero\n",
    "    \"\"\"\n",
    "    np.random.seed(nb_train)\n",
    "    x_train = np.random.rand(nb_train)\n",
    "    x_test = np.random.rand(nb_test)\n",
    "    if modele_gen == 'lineaire':\n",
    "        t_train = w[0] + x_train * w[1] + np.random.randn(nb_train) * bruit\n",
    "        t_test = w[0] + x_test * w[1] + np.random.randn(nb_test) * bruit\n",
    "    elif modele_gen == 'sin':\n",
    "        t_train = np.sin(x_train * w[1] * 2) + np.random.randn(nb_train) * bruit\n",
    "        t_test = np.sin(x_test * w[1] * 2) + np.random.randn(nb_test) * bruit\n",
    "    else:\n",
    "        t_train = np.tanh((x_train - 0.5) * w[1] * 2) + np.random.randn(nb_train) * bruit\n",
    "        t_test = np.tanh((x_test - 0.5) * w[1] * 2) + np.random.randn(nb_test) * bruit\n",
    "\n",
    "    return x_train, t_train, x_test, t_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def afficher_donnees_et_modele( x, t, scatter=True):\n",
    "    \"\"\"\n",
    "    afficher des donnees\n",
    "\n",
    "    x : vecteur de donnees\n",
    "    t : vecteur de cibles\n",
    "    scatter : variable determinant si on doit afficher une courbe ou des points\n",
    "    \"\"\"\n",
    "    x_mod = np.arange(0, 1, 0.01)\n",
    "\n",
    "    if modele_gen == 'lineaire':\n",
    "        t_mod = w[0] + x_mod * w[1]\n",
    "    elif modele_gen == 'sin':\n",
    "        t_mod = np.sin(x_mod * w[1] * 2)\n",
    "    else:\n",
    "        t_mod = np.tanh((x_mod - 0.5) * w[1] * 2)\n",
    "\n",
    "    if scatter is True:\n",
    "        plt.scatter(x, t)\n",
    "    else:\n",
    "        idx = np.argsort(x)\n",
    "        plt.plot(x[idx], t[idx], 'g')\n",
    "\n",
    "    plt.plot(x_mod, t_mod, 'k')\n",
    "    plt.ylim(ymin=-1.5, ymax=4.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fonction_base_polynomiale(x):\n",
    "    \"\"\"\n",
    "    Fonction de base qui projette la donnee x vers un espace polynomial tel que mentionne au chapitre 3.\n",
    "    Si x est un scalaire, alors phi_x sera un vecteur à M dimensions : (x^1,x^2,...,x^M)\n",
    "    Si x est un vecteur de N scalaires, alors phi_x sera un tableau 2D de taille NxM\n",
    "\n",
    "    NOTE : En mettant phi_x = x, on a une fonction de base lineaire qui fonctionne pour une regression lineaire\n",
    "    \"\"\"\n",
    "    # AJOUTER CODE ICI\n",
    "   \n",
    "    if(type(x) == int):\n",
    "        return np.array([x**i for i in range(1, m+1)]).reshape(m,1) # (x^1,x^2,...,x^M)\n",
    "    else:\n",
    "        x = x.reshape(-1,1)\n",
    "        for i in range(2,m+1):\n",
    "            x = np.hstack((x, (x[:, 0] ** i).reshape((len(x), 1))))\n",
    "        return x# 2D de taille NxM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test fonction_base_polynomiale : avec m = 10\n",
      " -> Si x est un scalaire : 2\n",
      "[[      2]\n",
      " [      4]\n",
      " [      8]\n",
      " [     16]\n",
      " [     32]\n",
      " [     64]\n",
      " [    128]\n",
      " [    256]\n",
      " [    512]\n",
      " [   1024]\n",
      " [   2048]\n",
      " [   4096]\n",
      " [   8192]\n",
      " [  16384]\n",
      " [  32768]\n",
      " [  65536]\n",
      " [ 131072]\n",
      " [ 262144]\n",
      " [ 524288]\n",
      " [1048576]]\n",
      "shape :(20, 1)\n",
      " -> Si x est un vecteur de n scalaires : [2, 3]\n",
      "[[         2          4          8         16         32         64\n",
      "         128        256        512       1024       2048       4096\n",
      "        8192      16384      32768      65536     131072     262144\n",
      "      524288    1048576]\n",
      " [         3          9         27         81        243        729\n",
      "        2187       6561      19683      59049     177147     531441\n",
      "     1594323    4782969   14348907   43046721  129140163  387420489\n",
      "  1162261467 -808182895]]\n",
      "Shape :(2, 20)\n"
     ]
    }
   ],
   "source": [
    "print(\"test fonction_base_polynomiale : avec m = 10\")\n",
    "print(\" -> Si x est un scalaire : 2\")\n",
    "print(fonction_base_polynomiale(2))\n",
    "print(\"shape :\"+str(fonction_base_polynomiale(2).shape))\n",
    "print(\" -> Si x est un vecteur de n scalaires : [2, 3]\")\n",
    "print(fonction_base_polynomiale(np.array([2, 3])))\n",
    "print(\"Shape :\"+str(fonction_base_polynomiale(np.array([2, 3])).shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recherche_hyperparametre(X, t):\n",
    "    \"\"\"\n",
    "    Validation croisee de type \"k-fold\" pour k=10 utilisee pour trouver \n",
    "    la meilleure valeur pour l'hyper-parametre M.\n",
    "\n",
    "    Le resultat est mis dans la variable M\n",
    "\n",
    "    X: vecteur de donnees\n",
    "    t: vecteur de cibles\n",
    "    \"\"\"\n",
    "    # AJOUTER CODE ICI\n",
    "    \n",
    "    \n",
    "    m = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def entrainement(X, t, using_sklearn=False):\n",
    "    \"\"\"\n",
    "    Entraîne la regression lineaire sur l'ensemble d'entraînement forme des\n",
    "    entrees ``X`` (un tableau 2D Numpy, ou la n-ieme rangee correspond à \n",
    "    l'entree x_n) et des cibles ``t`` (un tableau 1D Numpy ou le\n",
    "    n-ieme element correspond à la cible t_n). L'entraînement doit\n",
    "    utiliser le poids de regularisation specifie par ``lamb``.\n",
    "\n",
    "    Cette methode doit assigner le champs ``w`` au vecteur\n",
    "    (tableau Numpy 1D) de taille D+1, tel que specifie à la section 3.1.4\n",
    "    du livre de Bishop.\n",
    "\n",
    "    Lorsque using_sklearn=True, vous devez utiliser la classe \"Ridge\" de \n",
    "    la librairie sklearn (voir http://scikit-learn.org/stable/modules/linear_model.html)\n",
    "\n",
    "    Lorsque using_sklearn=False, vous devez implementer l'equation 3.28 du\n",
    "    livre de Bishop. Il est suggere que le calcul de ``w`` n'utilise\n",
    "    pas d'inversion de matrice, mais utilise plutôt une procedure\n",
    "    de resolution de systeme d'equations lineaires (voir np.linalg.solve).\n",
    "\n",
    "    Aussi, la variable membre M sert à projeter les variables X vers un \n",
    "    espace polynomiale de degre M(voir fonction fonction_base_polynomiale())\n",
    "\n",
    "    NOTE IMPORTANTE : lorsque M <= 0, il faut trouver la bonne valeur de M\n",
    "\n",
    "    \"\"\"\n",
    "    #AJOUTER CODE ICI\n",
    "    \n",
    "\n",
    "    phi_x = fonction_base_polynomiale(X)\n",
    "    phi_x = pd.DataFrame(phi_x)\n",
    "    l = len(phi_x)\n",
    "    w = np.array([0]*len(phi_x.columns))\n",
    "    \n",
    "    # using_sklearn=True\n",
    "    if(using_sklearn==True):\n",
    "        reg = linear_model.Ridge(alpha=.7)\n",
    "        fit = reg.fit(phi_x, t)\n",
    "        w = fit.coef_\n",
    "        \n",
    "    # using_sklearn=False\n",
    "    if(using_sklearn==False):\n",
    "        iterations = 100000\n",
    "        cost_history = []\n",
    "        \n",
    "        for iteration in range(iterations):\n",
    "            hypothesis = phi_x.dot(w)\n",
    "            loss = hypothesis-t\n",
    "            gradient = phi_x.T.dot(loss)/l\n",
    "            w = w - lamb*gradient\n",
    "            cost = np.sum((phi_x.dot(w)-t)**2)/(2*l)\n",
    "            cost_history.append(cost)\n",
    "            #print(cost)\n",
    "        plt.title('Fonction objectif J')\n",
    "        plt.xlabel('iterations')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.plot(cost_history)\n",
    "        plt.show()\n",
    "    return phi_x, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(x):\n",
    "    \"\"\"\n",
    "    Retourne la prediction de la regression lineaire\n",
    "    pour une entree, representee par un tableau 1D Numpy ``x``.\n",
    "\n",
    "    Cette methode suppose que la methode ``entrainement()``\n",
    "    a prealablement ete appelee. Elle doit utiliser le champs ``w``\n",
    "    afin de calculer la prediction y(x,w) (equation 3.1 et 3.3).\n",
    "    \"\"\"\n",
    "    # AJOUTER CODE ICI\n",
    "    y = W*x\n",
    "    return np.sum(y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erreur(t, prediction):\n",
    "    \"\"\"\n",
    "    Retourne l'erreur de la difference au carre entre\n",
    "    la cible ``t`` et la prediction ``prediction``.\n",
    "    \"\"\"\n",
    "    # AJOUTER CODE ICI\n",
    "    \"\"\" pas sure \"\"\"\n",
    "    return (t-prediction)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warning(erreur_test, erreur_apprentissage, bruit):\n",
    "    \"\"\"\n",
    "    Fonction qui affiche un WARNING à l'ecran lorsque les erreurs obtenues en fonction du bruit\n",
    "    indique une possibilite de sur- ou de sous-apprentissage\n",
    "\n",
    "    erreur_test: erreur obtenue sur l'ensemble de test\n",
    "    erreur_apprentissage: erreur obtenue sur l'ensemble d'apprentissage\n",
    "    bruit: magnitude du bruit\n",
    "    \"\"\"\n",
    "    # AJOUTER CODE ICI\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creer le gestionnaire de donnees et generer les donnees d'entraînement et de test\n",
    "[x_train, t_train, x_test, t_test] = generer_donnees()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainement du modele de regression\n",
    "phi_x, W = entrainement(x_train, t_train, using_sklearn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = fonction_base_polynomiale(x_test)\n",
    "x_test = pd.DataFrame(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions sur les ensembles 'entrainement et de test\n",
    "predictions_train = prediction(phi_x)\n",
    "predictions_test = prediction(x_test)\n",
    "#predictions_train = np.array([prediction(x) for x in x_train])\n",
    "#predictions_test = np.array([prediction(x) for x in x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calcul des erreurs\n",
    "erreurs_entrainement = np.array([erreur(t_n, p_n)\n",
    "                                 for t_n, p_n in zip(t_train, predictions_train)])\n",
    "erreurs_test = np.array([erreur(t_n, p_n)\n",
    "                         for t_n, p_n in zip(t_test, predictions_test)])\n",
    "\n",
    "print(\"Erreur d'entraînement :\", \"%.2f\" % erreurs_entrainement.mean())\n",
    "print(\"Erreur de test :\", \"%.2f\" % erreurs_test.mean())\n",
    "print(\"\")\n",
    "\n",
    "warning(erreurs_test.mean(), erreurs_entrainement.mean(), bruit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afficher_donnees_et_modele(phi_x[0], t_train, True)\n",
    "predictions_range = np.array([prediction(pd.DataFrame([x])) for x in np.arange(0, 1, 0.01)])\n",
    "afficher_donnees_et_modele(np.arange(0, 1, 0.01), predictions_range, False)\n",
    "\n",
    "if m >= 0:\n",
    "    plt.suptitle('Resultat SANS recherche d\\'hyperparametres')\n",
    "else:\n",
    "    plt.suptitle('Resultat AVEC recherche d\\'hyperparametres')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Comparaison entre l'entrainemment et la prédiction\")\n",
    "plt.scatter(x=pd.DataFrame(phi_x)[0],y= t_train)           \n",
    "plt.scatter(x=pd.DataFrame(phi_x)[0], y=predictions_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
