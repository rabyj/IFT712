{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sk=0: using_sklearn=False, sk=1: using_sklearn=True\n",
    "- modele_gen=lineaire, sin ou tanh\n",
    "- nb_train: nombre de donnees d'entrainement\n",
    "- nb_test: nombre de donnees de test\n",
    "- bruit: amplitude du bruit appliqué aux données\n",
    "- M: degré du polynome de la fonction de base (recherche d'hyperparametre lorsque M<0) \n",
    "- lambda: lambda utilisé par le modele de Ridge ( learning rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "skl = 1\n",
    "modele_gen = \"sin\"\n",
    "nb_train = 80 \n",
    "nb_test = 20\n",
    "bruit = 0.3 # dispersion\n",
    "m = 10\n",
    "lamb = 0.001 # learning rate\n",
    "w = [0.3, 4.1]  # Parametres du modele generatif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gestion Donnees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generer_donnees():\n",
    "    \"\"\"\n",
    "    Fonction qui genere des donnees de test et d'entrainement.\n",
    "\n",
    "    modele_gen : 'lineaire', 'sin' ou 'tanh'\n",
    "    nb_train : nb de donnees d'entrainement\n",
    "    nb_test : nb de donnees de test\n",
    "    bruit : amplitude du bruit (superieur ou egale a zero\n",
    "    \"\"\"\n",
    "    np.random.seed(nb_train)\n",
    "    x_train = np.random.rand(nb_train)\n",
    "    x_test = np.random.rand(nb_test)\n",
    "    if modele_gen == 'lineaire':\n",
    "        t_train = w[0] + x_train * w[1] + np.random.randn(nb_train) * bruit\n",
    "        t_test = w[0] + x_test * w[1] + np.random.randn(nb_test) * bruit\n",
    "    elif modele_gen == 'sin':\n",
    "        t_train = np.sin(x_train * w[1] * 2) + np.random.randn(nb_train) * bruit\n",
    "        t_test = np.sin(x_test * w[1] * 2) + np.random.randn(nb_test) * bruit\n",
    "    else:\n",
    "        t_train = np.tanh((x_train - 0.5) * w[1] * 2) + np.random.randn(nb_train) * bruit\n",
    "        t_test = np.tanh((x_test - 0.5) * w[1] * 2) + np.random.randn(nb_test) * bruit\n",
    "\n",
    "    return x_train, t_train, x_test, t_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def afficher_donnees_et_modele( x, t, scatter=True):\n",
    "    \"\"\"\n",
    "    afficher des donnees\n",
    "\n",
    "    x : vecteur de donnees\n",
    "    t : vecteur de cibles\n",
    "    scatter : variable determinant si on doit afficher une courbe ou des points\n",
    "    \"\"\"\n",
    "    x_mod = np.arange(0, 1, 0.01)\n",
    "\n",
    "    if modele_gen == 'lineaire':\n",
    "        t_mod = w[0] + x_mod * w[1]\n",
    "    elif modele_gen == 'sin':\n",
    "        t_mod = np.sin(x_mod * w[1] * 2)\n",
    "    else:\n",
    "        t_mod = np.tanh((x_mod - 0.5) * w[1] * 2)\n",
    "\n",
    "    if scatter is True:\n",
    "        plt.scatter(x, t)\n",
    "    else:\n",
    "        idx = np.argsort(x)\n",
    "        plt.plot(x[idx], t[idx], 'g')\n",
    "\n",
    "    plt.plot(x_mod, t_mod, 'k')\n",
    "    plt.ylim(ymin=-1.5, ymax=4.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creer le gestionnaire de donnees et generer les donnees d'entraînement et de test\n",
    "[x_train, t_train, x_test, t_test] = generer_donnees()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fonction_base_polynomiale(x):\n",
    "    \"\"\"\n",
    "    Fonction de base qui projette la donnee x vers un espace polynomial tel que mentionne au chapitre 3.\n",
    "    Si x est un scalaire, alors phi_x sera un vecteur à M dimensions : (x^1,x^2,...,x^M)\n",
    "    Si x est un vecteur de N scalaires, alors phi_x sera un tableau 2D de taille NxM\n",
    "\n",
    "    NOTE : En mettant phi_x = x, on a une fonction de base lineaire qui fonctionne pour une regression lineaire\n",
    "    \"\"\"\n",
    "    # AJOUTER CODE ICI\n",
    "   \n",
    "    if(type(x) == int):\n",
    "        return np.array([x**i for i in range(1, m+1)]).reshape(m,1) # (x^1,x^2,...,x^M)\n",
    "    else:\n",
    "        x = x.reshape(-1,1)\n",
    "        for i in range(2,m+1):\n",
    "            x = np.hstack((x, (x[:, 0] ** i).reshape((len(x), 1))))\n",
    "        return x# 2D de taille NxM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test fonction_base_polynomiale : avec m = 10\n",
      " -> Si x est un scalaire : 2\n",
      "[[   2]\n",
      " [   4]\n",
      " [   8]\n",
      " [  16]\n",
      " [  32]\n",
      " [  64]\n",
      " [ 128]\n",
      " [ 256]\n",
      " [ 512]\n",
      " [1024]]\n",
      "shape :(10, 1)\n",
      " -> Si x est un vecteur de n scalaires : [2, 3]\n",
      "[[    2     4     8    16    32    64   128   256   512  1024]\n",
      " [    3     9    27    81   243   729  2187  6561 19683 59049]]\n",
      "Shape :(2, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"test fonction_base_polynomiale : avec m = 10\")\n",
    "print(\" -> Si x est un scalaire : 2\")\n",
    "print(fonction_base_polynomiale(2))\n",
    "print(\"shape :\"+str(fonction_base_polynomiale(2).shape))\n",
    "print(\" -> Si x est un vecteur de n scalaires : [2, 3]\")\n",
    "print(fonction_base_polynomiale(np.array([2, 3])))\n",
    "print(\"Shape :\"+str(fonction_base_polynomiale(np.array([2, 3])).shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recherche_hyperparametre(X, t):\n",
    "    \"\"\"\n",
    "    Validation croisee de type \"k-fold\" pour k=10 utilisee pour trouver \n",
    "    la meilleure valeur pour l'hyper-parametre M.\n",
    "\n",
    "    Le resultat est mis dans la variable M\n",
    "\n",
    "    X: vecteur de donnees\n",
    "    t: vecteur de cibles\n",
    "    \"\"\"\n",
    "    # AJOUTER CODE ICI\n",
    "    \n",
    "    \n",
    "    m = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrainement(X, t, using_sklearn=False):\n",
    "    \"\"\"\n",
    "    Entraîne la regression lineaire sur l'ensemble d'entraînement forme des\n",
    "    entrees ``X`` (un tableau 2D Numpy, ou la n-ieme rangee correspond à \n",
    "    l'entree x_n) et des cibles ``t`` (un tableau 1D Numpy ou le\n",
    "    n-ieme element correspond à la cible t_n). L'entraînement doit\n",
    "    utiliser le poids de regularisation specifie par ``lamb``.\n",
    "\n",
    "    Cette methode doit assigner le champs ``w`` au vecteur\n",
    "    (tableau Numpy 1D) de taille D+1, tel que specifie à la section 3.1.4\n",
    "    du livre de Bishop.\n",
    "\n",
    "    Lorsque using_sklearn=True, vous devez utiliser la classe \"Ridge\" de \n",
    "    la librairie sklearn (voir http://scikit-learn.org/stable/modules/linear_model.html)\n",
    "\n",
    "    Lorsque using_sklearn=False, vous devez implementer l'equation 3.28 du\n",
    "    livre de Bishop. Il est suggere que le calcul de ``w`` n'utilise\n",
    "    pas d'inversion de matrice, mais utilise plutôt une procedure\n",
    "    de resolution de systeme d'equations lineaires (voir np.linalg.solve).\n",
    "\n",
    "    Aussi, la variable membre M sert à projeter les variables X vers un \n",
    "    espace polynomiale de degre M(voir fonction fonction_base_polynomiale())\n",
    "\n",
    "    NOTE IMPORTANTE : lorsque M <= 0, il faut trouver la bonne valeur de M\n",
    "\n",
    "    \"\"\"\n",
    "    #AJOUTER CODE ICI\n",
    "    if m <= 0:\n",
    "        recherche_hyperparametre(X, t)\n",
    "\n",
    "    phi_x = fonction_base_polynomiale(X)\n",
    "    w = [0, 1]\n",
    "    \n",
    "    # using_sklearn=True\n",
    "    if(using_sklearn==True):\n",
    "        reg = linear_model.Ridge(alpha=.5)\n",
    "        fit = reg.fit(phi_x, t)\n",
    "        w = fit.coef_\n",
    "        \n",
    "    # using_sklearn=False\n",
    "    if(using_sklearn==False):\n",
    "        iterations = 10000\n",
    "        w = np.random.rand(10)\n",
    "        cost_history = []\n",
    "        cost_history.append(costFunction(phi_x, t, w))\n",
    "\n",
    "        for iteration in range(1, iterations):\n",
    "            hypothesis = phi_x.dot(w)\n",
    "            loss = hypothesis-t\n",
    "            gradient = phi_x.T.dot(loss)/m\n",
    "            w = w - lamb*gradient\n",
    "            cost = np.sum((np.matmul(phi_x, w)-t)**2)/(2*m)\n",
    "            cost_history.append(cost)\n",
    "            #print(cost)\n",
    "            if cost_history[iteration-1] - cost_history[iteration] < 0.00001:\n",
    "                break\n",
    "        plt.title('Fonction objectif J')\n",
    "        plt.xlabel('iterations')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.plot(cost_history)\n",
    "        plt.show()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(x):\n",
    "    \"\"\"\n",
    "    Retourne la prediction de la regression lineaire\n",
    "    pour une entree, representee par un tableau 1D Numpy ``x``.\n",
    "\n",
    "    Cette methode suppose que la methode ``entrainement()``\n",
    "    a prealablement ete appelee. Elle doit utiliser le champs ``w``\n",
    "    afin de calculer la prediction y(x,w) (equation 3.1 et 3.3).\n",
    "    \"\"\"\n",
    "    # AJOUTER CODE ICI\n",
    "    \"\"\" il faut la calculer \"\"\"\n",
    "    w0 = 1 \n",
    "    y = w0 + x.reshape(-1,1) @ W.reshape(1,-1)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erreur(t, prediction):\n",
    "    \"\"\"\n",
    "    Retourne l'erreur de la difference au carre entre\n",
    "    la cible ``t`` et la prediction ``prediction``.\n",
    "    \"\"\"\n",
    "    # AJOUTER CODE ICI\n",
    "    \"\"\" pas sure \"\"\"\n",
    "    return (t-prediction)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warning(erreur_test, erreur_apprentissage, bruit):\n",
    "    \"\"\"\n",
    "    Fonction qui affiche un WARNING à l'ecran lorsque les erreurs obtenues en fonction du bruit\n",
    "    indique une possibilite de sur- ou de sous-apprentissage\n",
    "\n",
    "    erreur_test: erreur obtenue sur l'ensemble de test\n",
    "    erreur_apprentissage: erreur obtenue sur l'ensemble d'apprentissage\n",
    "    bruit: magnitude du bruit\n",
    "    \"\"\"\n",
    "    # AJOUTER CODE ICI\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creer le gestionnaire de donnees et generer les donnees d'entraînement et de test\n",
    "[x_train, t_train, x_test, t_test] = generer_donnees()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Entrainement du modele de regression\n",
    "entrainement(x_train, t_train, using_sklearn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions sur les ensembles d'entrainement et de test\n",
    "predictions_train = prediction(x_train)\n",
    "predictions_test = prediction(x_test)\n",
    "#predictions_train = np.array([prediction(x) for x in x_train])\n",
    "#predictions_test = np.array([prediction(x) for x in x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur d'entraînement : 1.26\n",
      "Erreur de test : 1.19\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calcul des erreurs\n",
    "erreurs_entrainement = np.array([erreur(t_n, p_n)\n",
    "                                 for t_n, p_n in zip(t_train, predictions_train)])\n",
    "erreurs_test = np.array([erreur(t_n, p_n)\n",
    "                         for t_n, p_n in zip(t_test, predictions_test)])\n",
    "\n",
    "print(\"Erreur d'entraînement :\", \"%.2f\" % erreurs_entrainement.mean())\n",
    "print(\"Erreur de test :\", \"%.2f\" % erreurs_test.mean())\n",
    "print(\"\")\n",
    "\n",
    "warning(erreurs_test.mean(), erreurs_entrainement.mean(), bruit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur absolue moyenne d'entraînement : 10.56\n",
      "Erreur absolue moyenne de test : 10.36\n"
     ]
    }
   ],
   "source": [
    "def meanAbsoluteError(y,x):\n",
    "        temp = np.sum(np.abs(y.reshape(-1,1) - x))\n",
    "        return (1/len(y)) * temp\n",
    "\n",
    "print(\"Erreur absolue moyenne d'entraînement :\", \"%.2f\" % meanAbsoluteError(t_train, predictions_train))\n",
    "print(\"Erreur absolue moyenne de test :\", \"%.2f\" % meanAbsoluteError(t_test,predictions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur quadratique moyenne d'entraînement : 3.55\n",
      "Erreur quadratique moyenne de test : 3.45\n"
     ]
    }
   ],
   "source": [
    "def meanSquareError(y,x):\n",
    "        temp = np.sum(np.power(y.reshape(-1,1) - x,2))\n",
    "        return np.sqrt((1/len(y)) * temp)\n",
    "    \n",
    "print(\"Erreur quadratique moyenne d'entraînement :\", \"%.2f\" % meanSquareError(t_train, predictions_train))\n",
    "print(\"Erreur quadratique moyenne de test :\", \"%.2f\" % meanSquareError(t_test,predictions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² d'entraînement : -116.16\n",
      "R² de test : -167.08\n"
     ]
    }
   ],
   "source": [
    "def r2(y,x):\n",
    "    temp1 = np.sum(np.power(y.reshape(-1,1) - x,2))\n",
    "    temp2 = np.sum(np.power(y - np.average(y),2))\n",
    "    return 1 - (temp1/temp2)\n",
    "\"\"\" neg parce que w0 est predeterminée\"\"\"\n",
    "print(\"R² d'entraînement :\", \"%.2f\" % r2(t_train, predictions_train))\n",
    "print(\"R² de test :\", \"%.2f\" % r2(t_test,predictions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage\n",
    "afficher_donnees_et_modele(x_train, t_train, True)\n",
    "predictions_range = np.array([prediction(x) for x in np.arange(0, 1, 0.01)])\n",
    "afficher_donnees_et_modele(np.arange(0, 1, 0.01), predictions_range, False)\n",
    "\n",
    "if m >= 0:\n",
    "    plt.suptitle('Resultat SANS recherche d\\'hyperparametres')\n",
    "else:\n",
    "    plt.suptitle('Resultat AVEC recherche d\\'hyperparametres')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
