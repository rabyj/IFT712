{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sk=0: using_sklearn=False, sk=1: using_sklearn=True\n",
    "- modele_gen=lineaire, sin ou tanh\n",
    "- nb_train: nombre de donnees d'entrainement\n",
    "- nb_test: nombre de donnees de test\n",
    "- bruit: amplitude du bruit appliqué aux données\n",
    "- M: degré du polynome de la fonction de base (recherche d'hyperparametre lorsque M<0) \n",
    "- lambda: lambda utilisé par le modele de Ridge ( learning rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "skl = 1\n",
    "modele_gen = \"sin\"\n",
    "nb_train = 80\n",
    "nb_test = 20\n",
    "bruit = 0.3 # dispersion\n",
    "m = 20\n",
    "lamb = 0.01 # learning rate\n",
    "w = [0.3, 4.1]  # Parametres du modele generatif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gestion Donnees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generer_donnees():\n",
    "    \"\"\"\n",
    "    Fonction qui genere des donnees de test et d'entrainement.\n",
    "\n",
    "    modele_gen : 'lineaire', 'sin' ou 'tanh'\n",
    "    nb_train : nb de donnees d'entrainement\n",
    "    nb_test : nb de donnees de test\n",
    "    bruit : amplitude du bruit (superieur ou egale a zero\n",
    "    \"\"\"\n",
    "    np.random.seed(nb_train)\n",
    "    x_train = np.random.rand(nb_train)\n",
    "    x_test = np.random.rand(nb_test)\n",
    "    if modele_gen == 'lineaire':\n",
    "        t_train = w[0] + x_train * w[1] + np.random.randn(nb_train) * bruit\n",
    "        t_test = w[0] + x_test * w[1] + np.random.randn(nb_test) * bruit\n",
    "    elif modele_gen == 'sin':\n",
    "        t_train = np.sin(x_train * w[1] * 2) + np.random.randn(nb_train) * bruit\n",
    "        t_test = np.sin(x_test * w[1] * 2) + np.random.randn(nb_test) * bruit\n",
    "    else:\n",
    "        t_train = np.tanh((x_train - 0.5) * w[1] * 2) + np.random.randn(nb_train) * bruit\n",
    "        t_test = np.tanh((x_test - 0.5) * w[1] * 2) + np.random.randn(nb_test) * bruit\n",
    "\n",
    "    return x_train, t_train, x_test, t_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "def afficher_donnees_et_modele( x, t, scatter=True):\n",
    "    \"\"\"\n",
    "    afficher des donnees\n",
    "\n",
    "    x : vecteur de donnees\n",
    "    t : vecteur de cibles\n",
    "    scatter : variable determinant si on doit afficher une courbe ou des points\n",
    "    \"\"\"\n",
    "    x_mod = np.arange(0, 1, 0.01)\n",
    "\n",
    "    if modele_gen == 'lineaire':\n",
    "        t_mod = w[0] + x_mod * w[1]\n",
    "    elif modele_gen == 'sin':\n",
    "        t_mod = np.sin(x_mod * w[1] * 2)\n",
    "    else:\n",
    "        t_mod = np.tanh((x_mod - 0.5) * w[1] * 2)\n",
    "\n",
    "    if scatter is True:\n",
    "        plt.scatter(x, t)\n",
    "    else:\n",
    "        idx = np.argsort(x)\n",
    "        plt.plot(x[idx], t[idx], 'g')\n",
    "\n",
    "    plt.plot(x_mod, t_mod, 'k')\n",
    "    plt.ylim(ymin=-1.5, ymax=4.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fonction_base_polynomiale(x):\n",
    "    \"\"\"\n",
    "    Fonction de base qui projette la donnee x vers un espace polynomial tel que mentionne au chapitre 3.\n",
    "    Si x est un scalaire, alors phi_x sera un vecteur à M dimensions : (x^1,x^2,...,x^M)\n",
    "    Si x est un vecteur de N scalaires, alors phi_x sera un tableau 2D de taille NxM\n",
    "\n",
    "    NOTE : En mettant phi_x = x, on a une fonction de base lineaire qui fonctionne pour une regression lineaire\n",
    "    \"\"\"\n",
    "    # AJOUTER CODE ICI\n",
    "   \n",
    "    if(type(x) == int):\n",
    "        return np.array([x**i for i in range(1, m+1)]).reshape(m,1) # (x^1,x^2,...,x^M)\n",
    "    else:\n",
    "        x = x.reshape(-1,1)\n",
    "        for i in range(2,m+1):\n",
    "            x = np.hstack((x, (x[:, 0] ** i).reshape((len(x), 1))))\n",
    "        return x# 2D de taille NxM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test fonction_base_polynomiale : avec m = 10\n",
      " -> Si x est un scalaire : 2\n",
      "shape :(20, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>32768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>65536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>131072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>262144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>524288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1048576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0         2\n",
       "1         4\n",
       "2         8\n",
       "3        16\n",
       "4        32\n",
       "5        64\n",
       "6       128\n",
       "7       256\n",
       "8       512\n",
       "9      1024\n",
       "10     2048\n",
       "11     4096\n",
       "12     8192\n",
       "13    16384\n",
       "14    32768\n",
       "15    65536\n",
       "16   131072\n",
       "17   262144\n",
       "18   524288\n",
       "19  1048576"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"test fonction_base_polynomiale : avec m = 10\")\n",
    "print(\" -> Si x est un scalaire : 2\")\n",
    "print(\"shape :\"+str(fonction_base_polynomiale(2).shape))\n",
    "pd.DataFrame(fonction_base_polynomiale(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> Si x est un vecteur de n scalaires : [2, 3]\n",
      "Shape :(2, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>1024</td>\n",
       "      <td>2048</td>\n",
       "      <td>4096</td>\n",
       "      <td>8192</td>\n",
       "      <td>16384</td>\n",
       "      <td>32768</td>\n",
       "      <td>65536</td>\n",
       "      <td>131072</td>\n",
       "      <td>262144</td>\n",
       "      <td>524288</td>\n",
       "      <td>1048576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "      <td>81</td>\n",
       "      <td>243</td>\n",
       "      <td>729</td>\n",
       "      <td>2187</td>\n",
       "      <td>6561</td>\n",
       "      <td>19683</td>\n",
       "      <td>59049</td>\n",
       "      <td>177147</td>\n",
       "      <td>531441</td>\n",
       "      <td>1594323</td>\n",
       "      <td>4782969</td>\n",
       "      <td>14348907</td>\n",
       "      <td>43046721</td>\n",
       "      <td>129140163</td>\n",
       "      <td>387420489</td>\n",
       "      <td>1162261467</td>\n",
       "      <td>-808182895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3    4    5     6     7      8      9       10      11  \\\n",
       "0   2   4   8  16   32   64   128   256    512   1024    2048    4096   \n",
       "1   3   9  27  81  243  729  2187  6561  19683  59049  177147  531441   \n",
       "\n",
       "        12       13        14        15         16         17          18  \\\n",
       "0     8192    16384     32768     65536     131072     262144      524288   \n",
       "1  1594323  4782969  14348907  43046721  129140163  387420489  1162261467   \n",
       "\n",
       "          19  \n",
       "0    1048576  \n",
       "1 -808182895  "
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\" -> Si x est un vecteur de n scalaires : [2, 3]\")\n",
    "print(\"Shape :\"+str(fonction_base_polynomiale(np.array([2, 3])).shape))\n",
    "pd.DataFrame(fonction_base_polynomiale(np.array([2, 3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recherche_hyperparametre(X, t):\n",
    "    \"\"\"\n",
    "    Validation croisee de type \"k-fold\" pour k=10 utilisee pour trouver \n",
    "    la meilleure valeur pour l'hyper-parametre M.\n",
    "\n",
    "    Le resultat est mis dans la variable M\n",
    "\n",
    "    X: vecteur de donnees\n",
    "    t: vecteur de cibles\n",
    "    \"\"\"\n",
    "    # AJOUTER CODE ICI\n",
    "    \n",
    "    \n",
    "    m = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def entrainement(X, t, using_sklearn=False):\n",
    "    \"\"\"\n",
    "    Entraîne la regression lineaire sur l'ensemble d'entraînement forme des\n",
    "    entrees ``X`` (un tableau 2D Numpy, ou la n-ieme rangee correspond à \n",
    "    l'entree x_n) et des cibles ``t`` (un tableau 1D Numpy ou le\n",
    "    n-ieme element correspond à la cible t_n). L'entraînement doit\n",
    "    utiliser le poids de regularisation specifie par ``lamb``.\n",
    "\n",
    "    Cette methode doit assigner le champs ``w`` au vecteur\n",
    "    (tableau Numpy 1D) de taille D+1, tel que specifie à la section 3.1.4\n",
    "    du livre de Bishop.\n",
    "\n",
    "    Lorsque using_sklearn=True, vous devez utiliser la classe \"Ridge\" de \n",
    "    la librairie sklearn (voir http://scikit-learn.org/stable/modules/linear_model.html)\n",
    "\n",
    "    Lorsque using_sklearn=False, vous devez implementer l'equation 3.28 du\n",
    "    livre de Bishop. Il est suggere que le calcul de ``w`` n'utilise\n",
    "    pas d'inversion de matrice, mais utilise plutôt une procedure\n",
    "    de resolution de systeme d'equations lineaires (voir np.linalg.solve).\n",
    "\n",
    "    Aussi, la variable membre M sert à projeter les variables X vers un \n",
    "    espace polynomiale de degre M(voir fonction fonction_base_polynomiale())\n",
    "\n",
    "    NOTE IMPORTANTE : lorsque M <= 0, il faut trouver la bonne valeur de M\n",
    "\n",
    "    \"\"\"\n",
    "    #AJOUTER CODE ICI\n",
    "    \n",
    "\n",
    "    phi_x = fonction_base_polynomiale(X)\n",
    "    phi_x = np.c_[np.ones(phi_x.shape[0]), phi_x]\n",
    "    phi_x = pd.DataFrame(phi_x)\n",
    "    l = len(phi_x)\n",
    "    w = np.array([0]*len(phi_x.columns))\n",
    "    \n",
    "    # using_sklearn=True\n",
    "    if(using_sklearn==True):\n",
    "        reg = linear_model.Ridge(alpha=.7)\n",
    "        fit = reg.fit(phi_x, t)\n",
    "        w = fit.coef_\n",
    "        \n",
    "    # using_sklearn=False\n",
    "    if(using_sklearn==False):\n",
    "        iterations = 100000\n",
    "        cost_history = []\n",
    "        \n",
    "        for iteration in range(iterations):\n",
    "            hypothesis = phi_x.dot(w)\n",
    "            loss = hypothesis-t\n",
    "            gradient = phi_x.T.dot(loss)/l\n",
    "            w = w - lamb*gradient\n",
    "            cost = np.sum((phi_x.dot(w)-t)**2)/(2*l)\n",
    "            cost_history.append(cost)\n",
    "            #print(cost)\n",
    "        plt.title('Fonction objectif J')\n",
    "        plt.xlabel('iterations')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.plot(cost_history)\n",
    "        plt.show()\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(x):\n",
    "    \"\"\"\n",
    "    Retourne la prediction de la regression lineaire\n",
    "    pour une entree, representee par un tableau 1D Numpy ``x``.\n",
    "\n",
    "    Cette methode suppose que la methode ``entrainement()``\n",
    "    a prealablement ete appelee. Elle doit utiliser le champs ``w``\n",
    "    afin de calculer la prediction y(x,w) (equation 3.1 et 3.3).\n",
    "    \"\"\"\n",
    "    # AJOUTER CODE ICI\n",
    "    y = W*x\n",
    "    return np.sum(y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erreur(t, prediction):\n",
    "    \"\"\"\n",
    "    Retourne l'erreur de la difference au carre entre\n",
    "    la cible ``t`` et la prediction ``prediction``.\n",
    "    \"\"\"\n",
    "    # AJOUTER CODE ICI\n",
    "    \"\"\" pas sure \"\"\"\n",
    "    return (t-prediction)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warning(erreur_test, erreur_apprentissage, bruit):\n",
    "    \"\"\"\n",
    "    Fonction qui affiche un WARNING à l'ecran lorsque les erreurs obtenues en fonction du bruit\n",
    "    indique une possibilite de sur- ou de sous-apprentissage\n",
    "\n",
    "    erreur_test: erreur obtenue sur l'ensemble de test\n",
    "    erreur_apprentissage: erreur obtenue sur l'ensemble d'apprentissage\n",
    "    bruit: magnitude du bruit\n",
    "    \"\"\"\n",
    "    # AJOUTER CODE ICI\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creer le gestionnaire de donnees et generer les donnees d'entraînement et de test\n",
    "[x_train, t_train, x_test, t_test] = generer_donnees()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainement du modele de regression\n",
    "W = entrainement(x_train, t_train, using_sklearn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = fonction_base_polynomiale(x_train)\n",
    "x_train = pd.DataFrame(x_train)\n",
    "x_test = fonction_base_polynomiale(x_test)\n",
    "x_test = pd.DataFrame(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions sur les ensembles 'entrainement et de test\n",
    "predictions_train = prediction(x_train)\n",
    "predictions_test = prediction(x_test)\n",
    "#predictions_train = np.array([prediction(x) for x in x_train])\n",
    "#predictions_test = np.array([prediction(x) for x in x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calcul des erreurs\n",
    "erreurs_entrainement = np.array([erreur(t_n, p_n)\n",
    "                                 for t_n, p_n in zip(t_train, predictions_train)])\n",
    "erreurs_test = np.array([erreur(t_n, p_n)\n",
    "                         for t_n, p_n in zip(t_test, predictions_test)])\n",
    "\n",
    "print(\"Erreur d'entraînement :\", \"%.2f\" % erreurs_entrainement.mean())\n",
    "print(\"Erreur de test :\", \"%.2f\" % erreurs_test.mean())\n",
    "print(\"\")\n",
    "\n",
    "warning(erreurs_test.mean(), erreurs_entrainement.mean(), bruit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afficher_donnees_et_modele(x_train[0], t_train, True)\n",
    "predictions_range = np.array([prediction(pd.DataFrame([x])) for x in np.arange(0, 1, 0.01)])\n",
    "afficher_donnees_et_modele(np.arange(0, 1, 0.01), predictions_range, False)\n",
    "\n",
    "if m >= 0:\n",
    "    plt.suptitle('Resultat SANS recherche d\\'hyperparametres')\n",
    "else:\n",
    "    plt.suptitle('Resultat AVEC recherche d\\'hyperparametres')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Comparaison entre l'entrainemment et la prédiction\")\n",
    "plt.scatter(x=x_train[0],y= t_train)           \n",
    "plt.scatter(x=x_train[0], y=predictions_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Comparaison entre test et la prédiction\")\n",
    "plt.scatter(x=x_test[0],y= t_test)           \n",
    "plt.scatter(x=x_test[0], y=predictions_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t_test)\n",
    "plt.plot(predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t_train)\n",
    "plt.plot(predictions_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
